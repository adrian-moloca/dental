version: '3.8'

services:
  # PostgreSQL 16 - Primary relational database
  postgres:
    image: postgres:16-alpine
    container_name: dental-postgres
    restart: unless-stopped
    ports:
      - "${POSTGRES_PORT:-5433}:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-dental_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-dental_password}
      POSTGRES_DB: ${POSTGRES_DB:-dental_db}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts/init.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
      - ./logs/postgres:/var/log/postgresql
    networks:
      - dental-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-dental_user} -d ${POSTGRES_DB:-dental_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # MongoDB 7 - Document database for flexible schemas
  mongodb:
    image: mongo:7-jammy
    container_name: dental-mongodb
    restart: unless-stopped
    ports:
      - "${MONGO_PORT:-27017}:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER:-admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD:-admin_password}
      MONGO_INITDB_DATABASE: ${MONGO_DB:-dental_documents}
    volumes:
      - mongodb_data:/data/db
      - mongodb_config:/data/configdb
      - ./logs/mongodb:/var/log/mongodb
    networks:
      - dental-network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: ["--wiredTigerCacheSizeGB", "1"]

  # Redis 7 - In-memory cache and session store
  redis:
    image: redis:7-alpine
    container_name: dental-redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6380}:6379"
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD:-redis_password}
    volumes:
      - redis_data:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf:ro
      - ./logs/redis:/var/log/redis
    networks:
      - dental-network
    healthcheck:
      test: ["CMD-SHELL", "redis-cli -p 6379 -a ${REDIS_PASSWORD:-redis_password} ping | grep PONG"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: >
      sh -c "
      if [ -f /usr/local/etc/redis/redis.conf ]; then
        redis-server /usr/local/etc/redis/redis.conf --requirepass ${REDIS_PASSWORD:-redis_password}
      else
        redis-server --requirepass ${REDIS_PASSWORD:-redis_password} --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
      fi
      "

  # RabbitMQ 3 - Message broker with management UI
  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: dental-rabbitmq
    restart: unless-stopped
    ports:
      - "${RABBITMQ_PORT:-5672}:5672"
      - "${RABBITMQ_MANAGEMENT_PORT:-15672}:15672"
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER:-dental_user}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-rabbitmq_password}
      RABBITMQ_DEFAULT_VHOST: ${RABBITMQ_VHOST:-dental}
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - rabbitmq_logs:/var/log/rabbitmq
      - ./config/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
      - ./config/rabbitmq-definitions.json:/etc/rabbitmq/definitions.json:ro
    networks:
      - dental-network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    hostname: dental-rabbitmq

  # OpenSearch 2 - Search and analytics engine
  opensearch:
    image: opensearchproject/opensearch:2
    container_name: dental-opensearch
    restart: unless-stopped
    ports:
      - "${OPENSEARCH_PORT:-9200}:9200"
      - "${OPENSEARCH_PERF_PORT:-9600}:9600"
    environment:
      cluster.name: dental-cluster
      node.name: dental-node-01
      discovery.type: single-node
      bootstrap.memory_lock: "true"
      OPENSEARCH_JAVA_OPTS: "-Xms512m -Xmx512m"
      OPENSEARCH_INITIAL_ADMIN_PASSWORD: ${OPENSEARCH_ADMIN_PASSWORD:-admin}
      DISABLE_INSTALL_DEMO_CONFIG: "false"
      DISABLE_SECURITY_PLUGIN: "${OPENSEARCH_DISABLE_SECURITY:-false}"
    volumes:
      - opensearch_data:/usr/share/opensearch/data
      - opensearch_logs:/usr/share/opensearch/logs
      - ./config/opensearch.yml:/usr/share/opensearch/config/opensearch.yml:ro
    networks:
      - dental-network
    healthcheck:
      test: ["CMD-SHELL", "curl -k -u admin:${OPENSEARCH_ADMIN_PASSWORD:-admin} https://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # OpenSearch Dashboards - Visualization and management UI
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2
    container_name: dental-opensearch-dashboards
    restart: unless-stopped
    ports:
      - "${OPENSEARCH_DASHBOARDS_PORT:-5601}:5601"
    environment:
      OPENSEARCH_HOSTS: '["https://opensearch:9200"]'
      OPENSEARCH_USERNAME: admin
      OPENSEARCH_PASSWORD: ${OPENSEARCH_ADMIN_PASSWORD:-admin}
      DISABLE_SECURITY_DASHBOARDS_PLUGIN: "${OPENSEARCH_DISABLE_SECURITY:-false}"
    volumes:
      - ./config/opensearch-dashboards.yml:/usr/share/opensearch-dashboards/config/opensearch_dashboards.yml:ro
    networks:
      - dental-network
    depends_on:
      opensearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f -u ${OPENSEARCH_USERNAME:-admin}:${OPENSEARCH_ADMIN_PASSWORD:-admin} http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  dental-network:
    driver: bridge
    name: dental-network
    ipam:
      driver: default
      config:
        - subnet: 172.25.0.0/16

volumes:
  postgres_data:
    driver: local
    name: dental-postgres-data
  mongodb_data:
    driver: local
    name: dental-mongodb-data
  mongodb_config:
    driver: local
    name: dental-mongodb-config
  redis_data:
    driver: local
    name: dental-redis-data
  rabbitmq_data:
    driver: local
    name: dental-rabbitmq-data
  rabbitmq_logs:
    driver: local
    name: dental-rabbitmq-logs
  opensearch_data:
    driver: local
    name: dental-opensearch-data
  opensearch_logs:
    driver: local
    name: dental-opensearch-logs
